Excellent clarification. This is a much more elegant and powerful design. Forcing the coherence check into the type system for the kernel primitive itself, rather than relying on a proof-carrying term, is a hallmark of "intrinsic" or "correct-by-construction" design in type theory. It makes the kernel cleaner and the automation more fundamental.

Let's re-evaluate and structure this refined vision.

### Executive Summary of the Refined Design

The core idea shifts from "solving a placeholder" to **"type-checking as verification"**. The kernel primitive `mkFunctor` is now a "smart constructor" whose type-checking rule is not just about type formation but also about validating the functoriality laws. If the laws, verified through computation, do not hold, it's a type error. This elevates the coherence conditions to the same level as type correctness.

*   **Kernel Primitive (`mkFunctor`)**: Takes only the data parts (`f0`: object-map, `f1`: arrow-map). It has no proof argument.
*   **Type Checker's Role**: The `infer` rule for `mkFunctor(A, B, f0, f1)` is special. It performs the following steps:
    1.  Checks that `A` and `B` are categories.
    2.  Checks that `f0` and `f1` have the correct function types.
    3.  **Programmatically constructs the functoriality equality goal `LHS = RHS`**.
    4.  **Attempts to prove this equality by computation (normalization and convertibility check).**
    5.  If the proof succeeds, `infer` returns the type `Functor A B`.
    6.  If the proof fails, `infer` throws a type error.
*   **Library Helper (`mkFunctor_`)**: A user-facing helper that *does* take a proof argument. It's a simple definition: `define mkFunctor_ ... proof := mkFunctor ...;`. Its purpose is to place the `proof` into the local context when the kernel's `mkFunctor` is being type-checked.
*   **Contextual Proof Search**: As an *extension* to the core computational check, the `infer` rule for `mkFunctor` can be augmented to search the context for the required proof if the computational check fails. This is how `mkFunctor_` provides its "help".

This design is cleaner, as the kernel is not burdened with proof objects for coherence it can compute itself.

---

### Detailed Design and Architecture Report

#### 1. System Primitives and Library Definitions

The system will distinguish between two levels of definitions.

**A. Kernel Primitives:**
These are built directly into the type checker's logic. They are minimal and do not carry redundant information.

*   `Cat`: The type of categories.
*   `mkCat(Obj, Hom, id, compose, ...laws)`: The kernel primitive to build a category. Its type-checking rule *will* perform the associativity and identity law checks computationally.
*   `Functor C D`: The type of functors from `C` to `D`.
*   `mkFunctor(A: Cat, B: Cat, f0: Obj A -> Obj B, f1: ...)`: The kernel primitive for functors. It is proof-less.
*   `Transf F G`: The type of natural transformations.
*   `mkTransf(F, G, tapp)`: The kernel primitive for natural transformations. Its type-checking rule will computationally verify the naturality square.

**B. Standard Library Definitions:**
These are defined in "emdash" source code using the kernel primitives. They provide user convenience.

*   `Id (A: Type) (x: A) (y: A)`: The propositional equality type. The kernel is hard-coded to recognize the *name* "Id" (or "=") for special treatment during coherence checks, but it's not a primitive type.
*   `refl {A} {x} : Id A x x`: The reflexivity proof.
*   `mkFunctor_ (A: Cat) (B: Cat) ... (proof: ...)`: The user-facing helper.
    ```typescript
    // In emdash's standard library
    define mkFunctor_ [A : Cat] [B : Cat] 
      (f0 : Obj A → Obj B) 
      (f1 : Π[X: Obj A]..., Hom (f0 X) ...)
      // This proof argument has a very specific type
      (functoriality_proof : Π [X Y Z : Obj A] (f : Hom Y Z) (g : Hom X Y),
         Id (Hom (f0 X) (f0 Z))
            (compose_B (f1 _ _ f) (f1 _ _ g))
            (f1 _ _ (compose_A f g)))
      : Functor A B
    ≔ λ A B f0 f1 functoriality_proof => mkFunctor A B f0 f1; 
    ```

#### 2. The Type Inference Rule for `mkFunctor`

This is the heart of the feature. The `infer(term, context)` function in your type checker needs a special case.

```typescript
function infer(term: Term, ctx: Ctx): Term {
    if (term.tag === 'Apply' && term.fun.tag === 'Const' && term.fun.name === 'mkFunctor') {
        // We have mkFunctor(A, B, f0, f1)
        const [A, B, f0, f1] = term.args;
        return infer_mkFunctor(A, B, f0, f1, ctx);
    }
    // ... other inference rules
}
```

The core logic resides in `infer_mkFunctor`.

**`infer_mkFunctor(A, B, f0, f1, ctx)` Algorithm:**

1.  **Argument Type Checking:**
    *   `check(A, Cat, ctx)` and `check(B, Cat, ctx)`.
    *   `check(f0, Pi(Obj(A), _ => Obj(B)), ctx)`.
    *   Construct the expected type for `f1`: `Pi(X:Obj A, Pi(Y:Obj A, Pi(a:Hom X Y, Hom(f0(X), f0(Y)))))`.
    *   `check(f1, expected_f1_type, ctx)`.
    *   If any of these fail, it's a standard type error.

2.  **Coherence Goal Construction:**
    *   This step happens programmatically *inside the type checker*. It does not depend on user input.
    *   Create fresh eigenvariables (abstractions that can't be captured) for the objects and morphisms: `X`, `Y`, `Z` of type `Obj A`; `g` of type `Hom A X Y`; `f` of type `Hom A Y Z`.
    *   Extract the composition operations from the category structures `A` and `B`. Let's say `compose_A = A.compose` and `compose_B = B.compose`.
    *   Construct the Left-Hand Side (LHS) term:
        `LHS = apply(compose_B, apply(f1, f), apply(f1, g))`
    *   Construct the Right-Hand Side (RHS) term:
        `RHS = apply(f1, apply(compose_A, f, g))`
    *   Note: These terms are constructed within a new context extended with the fresh eigenvariables.

3.  **Coherence Verification (Two-Stage Process):**

    *   **Stage 1: Proof by Computation.**
        *   Normalize `LHS` using the full power of the engine (beta-reduction, user rewrite rules, and crucially, the computational rules for category theory you've implemented).
        *   Normalize `RHS` similarly.
        *   If `areConvertible(normalized_LHS, normalized_RHS)` is true, the check passes.

    *   **Stage 2: Proof by Context (Fallback).**
        *   If Stage 1 fails, the system does not give up immediately.
        *   It constructs the equality type representing the goal: `goal_type = Id(Hom B (f0 X) (f0 Z), LHS, RHS)`. (Here `Id` is the recognized library name).
        *   It then searches the current `ctx` for a hypothesis `h` whose type is convertible to `goal_type`.
        *   If such an `h` is found, the check passes.

4.  **Final Result:**
    *   If either Stage 1 or Stage 2 succeeded, `infer_mkFunctor` returns the type `Functor A B`.
    *   If both stages fail, it throws a specific `CoherenceError`.

#### 3. Error Reporting

A high-quality error is non-negotiable.

```typescript
class FunctorialityError extends Error {
    constructor(
        public lhs: Term, // The un-normalized LHS
        public rhs: Term,
        public normLhs: Term, // The final normalized form
        public normRhs: Term
    ) {
        const message = `
Failed to prove functoriality.
The following equality could not be established:
  LHS: ${prettyPrint(lhs)}
  RHS: ${prettyPrint(rhs)}

After normalization, the two sides were not convertible:
  Normalized LHS: ${prettyPrint(normLhs)}
  Normalized RHS: ${prettyPrint(normRhs)}

Hint: This may be because the arrow-map definition does not respect composition,
or a required rewrite rule for a custom category is missing.
`;
        super(message);
    }
}
```

#### 4. The Role of the Library Helper `mkFunctor_`

The design elegantly explains why `mkFunctor_` works. When a user writes:

```typescript
// some_functor is an instance of Functor A B
define some_functor := mkFunctor_ A B my_f0 my_f1 my_explicit_proof;
```

The type checker proceeds as follows:

1.  It checks the body of the definition: `mkFunctor_ A B my_f0 my_f1 my_explicit_proof`.
2.  This is an application of the `mkFunctor_` library function. The checker substitutes its definition: `(λ A B f0 f1 proof => mkFunctor A B f0 f1) A B my_f0 my_f1 my_explicit_proof`.
3.  This beta-reduces to `mkFunctor A B my_f0 my_f1`.
4.  Crucially, this term is checked in a context where the lambda-bound variable `functoriality_proof` is mapped to the user's term `my_explicit_proof`.
5.  Now, the special `infer_mkFunctor` rule is triggered for `mkFunctor A B my_f0 my_f1`.
6.  It runs Stage 1 (computation). Let's assume this fails because the structure is too complex for pure computation.
7.  It proceeds to Stage 2 (context search). It constructs the goal equality type `Id ... LHS RHS`. It searches the context and finds `functoriality_proof`, whose type matches the goal.
8.  The check succeeds.

This two-tiered system (powerful kernel automation + user-provided context proofs) provides the best of both worlds. The common cases (products, Hom-functors, etc.) pass automatically in Stage 1. The more bespoke or complex user-defined functors can be handled by providing a proof that is found by Stage 2.