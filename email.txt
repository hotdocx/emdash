[FOM] Autoformalization getting easy?
Inbox
Summarize this email

Josef Urban josef.urban@gmail.com via lists.ugent.be 
Thu, Jan 8, 11:39 AM
to fom

I have put on arxiv a paper with quite simple and cheap recipes that already led to automated formalization of quite a bit of topology from the Munkres textbook: https://arxiv.org/abs/2601.03298 .

It's done from scratch (using only a basic set-theoretical library) and with a relatively little-known proof assistant (Chad Brown's Megalodon).

I encourage everyone interested to try - already with the common $20/month LLM subscriptions one can get pretty far. 

I think if more people start doing this, we may have a lot of math (auto)formalized by the end 2026 (perhaps in multiple - and even quite arbitrary - proof assistants).

Best,
Josef

Buzzard, Kevin M k.buzzard@imperial.ac.uk via imperiallondon.onmicrosoft.com 
Thu, Jan 8, 10:44 PM
to fom@lists.ugent.be, Josef

I have experimented with autoformalization in Lean and the two main things that concern me are

Definitions;
Technical debt.

Definitions: whilst a proof assistant can of course check that a proof is valid, it cannot check that a definition corresponds to what humans mean (e.g. it can mangle an axiom but the code will still compile). My impression is that formalizing definitions at research level remains a big bottleneck in this area; we've seen AI successfully being used to attack formal versions of Erdos problems recently, but these problems are typically extremely easy to state in any proof assistant that has basic concepts (natural/real numbers, polynomials, finite sets etc) and it is not a coincidence that this is where the successes have been; no proof assistant can understand any of the main conjectures in the Langlands program right now because the (very complex) definitions have not yet been formalized.

Technical debt: my experience is that whilst AI can write code, proof assistant languages are very niche and as a result these systems often write very crappy code. My estimate right now is that something like Claude code is writing Lean code which is about 10x as long as what an expert human would write. I am unclear about whether this will be problematic long-term; what I do know is that  AI=generated proofs are extremely unlikely to make it into Lean's mathematics library mathlib because a human reviewer will say "this code is awful" and the person who submitted the code will typically respond "well I don't know the first thing about Lean, I just got this machine to do it, so I can't really fix this". Perhaps machines will learn to write much better code but I am not convinced that they will be writing mathlib-standard code in 2026. One of the big problems with unidiomatic proofs is that they are much harder to maintain. Perhaps AI can learn how to maintain them though? Another issue is that they are simply very slow; it already takes hours to compile Lean's mathematics library, and if this becomes days then this will become more problematic (although perhaps lean's new module system will fix this).

The other question which Josef's post raises is the value of having libraries written in many languages. Instinctively this sounds to me like a good idea but in practice I wonder whether the disadvantages outweigh the advantages. If one is working on formalizing the foundations of mathematics then choice of prover might become hugely important e.g. it was pointed out recently on the Lean Zulip that because AC is basically embedded into the system in such an aggressive way, it would be painful (but not impossible) to prove things like "the well-ordering principle is equivalent to the axiom of choice" because the system will just accidentally use the axiom of choice everywhere unless one fights really hard to stop it doing so. But if on the other hand one is just working in Langlands and doesn't even really care about whether it's powered by set theory or type theory then it will become painful if you need theorem X proved in proof assistant A and theorem Y proved in proof assistant B; perhaps the easiest way to proceed here is simply to choose one proof assistant and then port the proof (manually?). 
From: fom-request@lists.ugent.be <fom-request@lists.ugent.be> on behalf of Josef Urban <josef.urban@gmail.com>
Sent: Thursday, January 8, 2026 02:35
To: fom@lists.ugent.be <fom@lists.ugent.be>
Subject: [FOM] Autoformalization getting easy?
 
This email from josef.urban@gmail.com originates from outside Imperial. Do not click on links and attachments unless you recognise the sender. If you trust the sender, add them to your safe senders list to disable email stamping for this address.


Josef Urban josef.urban@gmail.com via lists.ugent.be 
Thu, Jan 22, 10:48 PM (10 days ago)
to fom

A brief update on this: 

I have now used a similar method to automatically formalize [1,2] the Urysohn Metrization theorem in John Harrison's HOL Light system (used e.g. for Tom Hales's Flyspeck project).

This is quite a different ITP system from Brown's Megalodon. 

Also, the formalization is not done from scratch here, but builds on John's extensive topology library [3].

Josef


[1] https://github.com/JUrban/hol-light-autoformalize1/blob/13cb81377ced26c67755ca05af537f243b35e162/Multivariate/urys_metriz.ml

[2] https://github.com/JUrban/hol-light-autoformalize1/commit/13cb81377ced26c67755ca05af537f243b35e162

[3] https://github.com/jrh13/hol-light/blob/master/Multivariate/metric.ml